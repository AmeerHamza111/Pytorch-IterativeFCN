{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FCN_MAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDBLz_MZPqre",
        "colab_type": "code",
        "outputId": "4b6bb7a6-2ef1-4acb-8998-bf32a191e462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeX8Zxx_RJR-",
        "colab_type": "code",
        "outputId": "553b8404-c427-43a9-fdf1-9ef6f04976ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "!pip install SimpleITK\n",
        "!pip install medpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.6/dist-packages (1.2.2)\n",
            "Requirement already satisfied: medpy in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: SimpleITK>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from medpy) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from medpy) (1.16.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from medpy) (1.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVsQZVUIProW",
        "colab_type": "code",
        "outputId": "e45382af-e5f5-4734-b311-d22a846769ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        }
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu Sep 19 11:21:22 2019\n",
        "\n",
        "@author: Gabriel Hsu\n",
        "\"\"\"\n",
        "from __future__ import print_function, division\n",
        "import argparse\n",
        "import time\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "from model import iterativeFCN\n",
        "from dataset import CSI_Dataset\n",
        "from metrics import DiceCoeff, ASSD\n",
        "\n",
        "def seg_loss(pred, target, weight):\n",
        "    size = pred.shape[0]\n",
        "    FP = torch.sum(weight*(1-target)*pred)\n",
        "    FN = torch.sum(weight*(1-pred)*target)\n",
        "    return FP/size, FN/size\n",
        "    \n",
        "#%%\n",
        "def train(args, model, device, train_loader, optimizer, epoch, max_epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    total_dice = 0\n",
        "    \n",
        "    for batch_idx, (img_patch, ins_patch, gt_patch, weight, c_label) in enumerate(train_loader):\n",
        "        \n",
        "        print('retrive patch')\n",
        "        \n",
        "        #pick a random scan\n",
        "        optimizer.zero_grad()\n",
        "        img_patch = img_patch.float()\n",
        "        ins_patch = ins_patch.float()\n",
        "        gt_patch = gt_patch.float()\n",
        "        c_label = c_label.float()\n",
        "        \n",
        "        \n",
        "        #concatenate the img_patch and ins_patch\n",
        "        input_patch = torch.cat((img_patch, ins_patch), dim=1)\n",
        "        input_patch, gt_patch, weight, c_label = input_patch.to(device), gt_patch.to(device), weight.to(device), c_label.to(device)\n",
        "        \n",
        "        print('fin de retrieve')\n",
        "        \n",
        "        print('calulation')\n",
        "        S, C = model(input_patch)        \n",
        "        \n",
        "\n",
        "        lamda = 0.1\n",
        "        \n",
        "        #segloss \n",
        "        FP, FN = seg_loss(S, gt_patch, weight) \n",
        "        \n",
        "        s_loss = lamda * FP + FN\n",
        "        c_loss = -1*c_label*torch.log(C)-(1-c_label)*torch.log(1-C)\n",
        "\n",
        "\n",
        "        total_loss = s_loss + c_loss\n",
        "        \n",
        "        #d_score = DiceCoeff(torch.round(S.detach()), gt_patch)\n",
        "        #optimize the parameters\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        print('fin de cal')\n",
        "        \n",
        "        train_loss += total_loss.item()\n",
        "        #total_dice += d_score\n",
        "        \n",
        "    return train_loss/len(train_loader)\n",
        "\n",
        "\n",
        "def test(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    total_dice = 0\n",
        "    \n",
        "    for batch_idx, (img_patch, ins_patch, gt_patch, weight, c_label) in enumerate(test_loader):\n",
        "\n",
        "        img_patch = img_patch.float()\n",
        "        ins_patch = ins_patch.float()\n",
        "        gt_patch = gt_patch.float()\n",
        "        c_label = c_label.float()\n",
        "        \n",
        "        input_patch = torch.cat((img_patch, ins_patch), dim=1)\n",
        "        input_patch, gt_patch, weight, c_label = input_patch.to(device), gt_patch.to(device), weight.to(device), c_label.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            S, C = model(input_patch.float())\n",
        " \n",
        "\n",
        "        \n",
        "        lamda = 0.1\n",
        "        \n",
        "        #segloss \n",
        "        FP, FN = seg_loss(S, gt_patch, weight) \n",
        "        \n",
        "        s_loss = lamda * FP + FN\n",
        "        c_loss = -1*c_label*torch.log(C)-(1-c_label)*torch.log(1-C)\n",
        "        #closs\n",
        "        c_loss = -1*c_label*torch.log(C)-(1-c_label)*torch.log(1-C)\n",
        "\n",
        "        total_loss = s_loss + c_loss\n",
        "        #d_score = DiceCoeff(torch.round(S.detach()), gt_patch)\n",
        "\n",
        "        \n",
        "        test_loss += total_loss.item()\n",
        "        #total_dice += d_score\n",
        "        \n",
        "        \n",
        "    return test_loss/len(test_loader)\n",
        "    \n",
        "#%%Main\n",
        "if  __name__ == \"__main__\" :   \n",
        "    # Version of Pytorch\n",
        "    print(\"Pytorch Version:\", torch.__version__)\n",
        "    \n",
        "    # Training args\n",
        "    parser = argparse.ArgumentParser(description='Fully Convolutional Network')\n",
        "    parser.add_argument('--batch-size', type=int, default=1, metavar='N',\n",
        "                        help='input batch size for training (default: 64)')\n",
        "    parser.add_argument('--test-batch-size', type=int, default=1, metavar='N',\n",
        "                        help='input batch size for testing (default: 1000)')\n",
        "    parser.add_argument('--epochs', type=int, default=7000, metavar='N',\n",
        "                        help='number of epochs to train (default: 10)')\n",
        "    parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n",
        "                        help='learning rate (default: 0.01)')\n",
        "    parser.add_argument('--momentum', type=float, default=0.99, metavar='M',\n",
        "                        help='SGD momentum (default: 0.5)')\n",
        "    parser.add_argument('--no-cuda', action='store_true', default=True,\n",
        "                        help='disables CUDA training')\n",
        "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
        "                        help='random seed (default: 1)')\n",
        "    parser.add_argument('--log-interval', type=int, default=1000, metavar='N',\n",
        "                        help='how many batches to wait before logging training status')\n",
        "    \n",
        "    parser.add_argument('--save-model', action='store_true', default=True,\n",
        "                        help='For Saving the current Model')\n",
        "    \n",
        "    \n",
        "    args = parser.parse_known_args()[0]\n",
        "    #args = parser.parse_args()\n",
        "\n",
        "    # Use GPU if it is available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    #root directory of dataset\n",
        "    data_root = './drive/My Drive/isotropic_dataset'\n",
        "    \n",
        "    \n",
        "    # Create FCN\n",
        "    model = iterativeFCN().to('cuda')\n",
        "    model.load_state_dict(torch.load('./drive/My Drive/IterativeFCN.pth'))\n",
        "\n",
        "\n",
        "    batch_size = args.batch_size\n",
        "    batch_size_valid = batch_size\n",
        "\n",
        "    \n",
        "    train_set = CSI_Dataset(data_root, subset='train')\n",
        "    test_set = CSI_Dataset(data_root, subset='test')\n",
        "    \n",
        "    train_loader = DataLoader(\n",
        "        train_set,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_set,\n",
        "        batch_size=batch_size_valid\n",
        "    )\n",
        "    \n",
        "#%%    \n",
        "    #optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "    \n",
        "    train_loss = []\n",
        "    train_dicescore = []\n",
        "    test_loss = []\n",
        "    test_dicescore = []\n",
        "    best_test_dicescore = -1\n",
        "    \n",
        "    print('start training')\n",
        "    \n",
        "    start_time = time.time()\n",
        "    # Start Training\n",
        "    for epoch in range(1, args.epochs+1):\n",
        "        #train loss\n",
        "        t_loss  = train(args, model, device, train_loader, optimizer, epoch, args.epochs)\n",
        "        print('Train Epoch: {} \\t Loss: {:.6f}\\t'.format(\n",
        "            epoch, t_loss))\n",
        "        \n",
        "        # validation loss\n",
        "        v_loss = test(args, model, device, test_loader)\n",
        "        print('Validation Epoch: {} \\t Loss: {:.6f}\\t'.format(\n",
        "            epoch, v_loss))\n",
        "\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        #print('current memory allocated: {}'.format(torch.cuda.memory_allocated() / 1024 ** 2))\n",
        "        #print('max memory allocated: {}'.format(torch.cuda.max_memory_allocated() / 1024 ** 2))\n",
        "        #print('cached memory: {}'.format(torch.cuda.memory_cached() / 1024 ** 2))\n",
        "             \n",
        "            \n",
        "        train_loss.append(t_loss)\n",
        "        test_loss.append(v_loss)\n",
        "        test_dicescore.append(v_mean_dice)\n",
        "        \n",
        "        if v_mean_dice > best_test_dicescore:\n",
        "            best_test_dicescore = v_mean_dice\n",
        "            print('--- Saving model at Dice Score:{:.2f}% ---'.format(100 *  best_test_dicescore))\n",
        "        \n",
        "        torch.save(model.state_dict(),'./drive/My Drive/IterativeFCN.pth')    \n",
        "        \n",
        "        print('-------------------------------------------------------')\n",
        "        \n",
        "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "        \n",
        "    print(\"training:\", len(train_loader))\n",
        "    print(\"validation:\", len(test_loader))\n",
        "    x = list(range(1, args.epochs+1))\n",
        "    #plot train/validation loss versus epoch\n",
        "    plt.figure()\n",
        "    plt.title(\"Train/Validation Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Total Loss\")\n",
        "    plt.plot(x, train_loss,label=\"train loss\")\n",
        "    plt.plot(x, test_loss, color='red', label=\"validation loss\")\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    \n",
        "    #plot train/validation loss versus epoch\n",
        "    plt.figure()\n",
        "    plt.title(\"Train/Validation Dice Score\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Mean IOU\")\n",
        "#    plt.plot(x, train_dicescore,label=\"train iou\")\n",
        "    plt.plot(x, test_dicescore, color='red', label=\"validation iou\")\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "    # test set\n",
        "    print(\"Best Test Mean Dice Score:\",  best_test_dicescore)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pytorch Version: 1.1.0\n",
            "num_channel 64\n",
            "start training\n",
            "retrive patch\n",
            "fin de retrieve\n",
            "calulation\n",
            "fin de cal\n",
            "retrive patch\n",
            "fin de retrieve\n",
            "calulation\n",
            "fin de cal\n",
            "retrive patch\n",
            "fin de retrieve\n",
            "calulation\n",
            "fin de cal\n",
            "retrive patch\n",
            "fin de retrieve\n",
            "calulation\n",
            "fin de cal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ff7f62ef6328>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m#train loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mt_loss\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         print('Train Epoch: {} \\t Loss: {:.6f}\\t'.format(\n\u001b[1;32m    199\u001b[0m             epoch, t_loss))\n",
            "\u001b[0;32m<ipython-input-1-ff7f62ef6328>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, train_loader, optimizer, epoch, max_epoch)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fin de cal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;31m#total_dice += d_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}