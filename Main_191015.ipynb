{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main_191015.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leohsuofnthu/Pytorch-IterativeFCN/blob/master/Main_191015.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lTjJqrezvcQ",
        "colab_type": "code",
        "outputId": "0d8aee2b-750a-4a57-a59f-9687c26af9fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyCHkxyLz7r2",
        "colab_type": "code",
        "outputId": "af79beb7-1b50-4ee8-d6f3-3b0703dc8b74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "!pip install SimpleITK\n",
        "!pip install medpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting SimpleITK\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/06/f3a67ef0e108d18840fd5e83f831d5ef1710ba46f05465fc50f9a505b518/SimpleITK-1.2.3-cp36-cp36m-manylinux1_x86_64.whl (42.5MB)\n",
            "\u001b[K     |████████████████████████████████| 42.5MB 1.5MB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-1.2.3\n",
            "Collecting medpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/70/c1fd5dd60242eee81774696ea7ba4caafac2bad8f028bba94b1af83777d7/MedPy-0.4.0.tar.gz (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from medpy) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from medpy) (1.16.5)\n",
            "Requirement already satisfied: SimpleITK>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from medpy) (1.2.3)\n",
            "Building wheels for collected packages: medpy\n",
            "  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for medpy: filename=MedPy-0.4.0-cp36-cp36m-linux_x86_64.whl size=753438 sha256=5c50cb73052264c4452ba0f2d4d983b921ed5b274d2199dff99f0f27e7993119\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/c9/9c/2c6281c7a72b9fb1570862a4f028af7ce38405008354fbf870\n",
            "Successfully built medpy\n",
            "Installing collected packages: medpy\n",
            "Successfully installed medpy-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O95a1aStKHRI",
        "colab_type": "code",
        "outputId": "a60ec914-e1a8-4407-9bef-7a09b7287aa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\"\n",
        "Training and Evaluation\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu Sep 19 11:21:22 2019\n",
        "\n",
        "@author: Gabriel Hsu\n",
        "\"\"\"\n",
        "from __future__ import print_function, division\n",
        "import os\n",
        "import argparse\n",
        "import time\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from model import iterativeFCN\n",
        "from dataset import CSI_Dataset\n",
        "from metrics import DiceCoeff, ASSD\n",
        "\n",
        "import SimpleITK as sitk\n",
        "\n",
        "def seg_loss(pred, target, weight):\n",
        "    FP = torch.sum(weight*(1-target)*pred)\n",
        "    FN = torch.sum(weight*(1-pred)*target)\n",
        "    return FP, FN\n",
        "    \n",
        "#%%\n",
        "def train_single(args, model, device, img_patch, ins_patch, gt_patch, weight, c_label, optimizer):\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "  \n",
        "    model.train()\n",
        "    correct = 0\n",
        "    \n",
        "    img_patch = img_patch.float()\n",
        "    ins_patch = ins_patch.float()\n",
        "    gt_patch = gt_patch.float()\n",
        "    weight = weight.float()\n",
        "    c_label = c_label.float()\n",
        "    \n",
        "    \n",
        "    #pick a random scan\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    #concatenate the img_patch and ins_patch\n",
        "    input_patch = torch.cat((img_patch, ins_patch), dim=1)\n",
        "    input_patch, gt_patch, weight, c_label = input_patch.to(device), gt_patch.to(device), weight.to(device), c_label.to(device)\n",
        "    \n",
        "    \n",
        "    S, C = model(input_patch.float())        \n",
        "    \n",
        "    \n",
        "    #Calculate DiceCoeff\n",
        "    pred = torch.round(S).detach()\n",
        "    train_dice_coef =  DiceCoeff(pred, gt_patch.detach())\n",
        "    \n",
        "    print( train_dice_coef*100, '%')\n",
        "    \n",
        "    #compute the loss\n",
        "    lamda = 0.1\n",
        "    \n",
        "    #segloss \n",
        "    FP, FN = seg_loss(S, gt_patch, weight) \n",
        " \n",
        "    s_loss = lamda*FP + FN\n",
        "    \n",
        "    c_loss = F.binary_cross_entropy(torch.unsqueeze(C, dim=0), c_label)\n",
        "\n",
        "    print(s_loss.item(), c_loss.item())\n",
        "    \n",
        "    train_loss = s_loss + c_loss\n",
        "    \n",
        "    \n",
        "    \n",
        "    if C.round() == c_label:\n",
        "        correct = 1\n",
        "    \n",
        "    #optimize the parameters\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return train_loss.item(), correct, train_dice_coef\n",
        "\n",
        "def test_single(args, model, device, img_patch, ins_patch, gt_patch, weight, c_label):\n",
        "    \n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    \n",
        "    img_patch = img_patch.float()\n",
        "    ins_patch = ins_patch.float()\n",
        "    gt_patch = gt_patch.float()\n",
        "    weight = weight.float()\n",
        "    c_label = c_label.float()\n",
        "    \n",
        "    input_patch = torch.cat((img_patch, ins_patch), dim=1)\n",
        "    input_patch, gt_patch, weight, c_label = input_patch.to(device), gt_patch.to(device), weight.to(device), c_label.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        S, C = model(input_patch.float())\n",
        "        \n",
        "    \"\"\"\n",
        "    pred = torch.squeeze(S.to('cpu'))\n",
        "    sitk.WriteImage(sitk.GetImageFromArray(pred.numpy()), './pred.nrrd', True)\n",
        "    \n",
        "    gtt = torch.squeeze(gt_patch.to('cpu'))\n",
        "    sitk.WriteImage(sitk.GetImageFromArray(gtt.numpy()), './gt.nrrd', True)\n",
        "    \"\"\"\n",
        "    \n",
        "    #Calculate DiceCoeff\n",
        "    pred = torch.round(S).detach()\n",
        "    test_dice_coef =  DiceCoeff(pred, gt_patch.detach())  \n",
        "    \n",
        "    print( test_dice_coef*100, '%')\n",
        "    \n",
        "    #compute the loss\n",
        "    lamda = 0.1\n",
        "    \n",
        "    #segloss \n",
        "    FP, FN = seg_loss(S, gt_patch, weight) \n",
        "    \n",
        "    s_loss = lamda*FP + FN\n",
        "    \n",
        "    c_loss = F.binary_cross_entropy(torch.unsqueeze(C, dim=0), c_label)\n",
        "    \n",
        "    \n",
        "    print(s_loss.item(), c_loss.item())\n",
        "    \n",
        "    if C.round() == c_label:\n",
        "        correct = 1\n",
        "\n",
        "    test_loss = s_loss + c_loss\n",
        "    \n",
        "        \n",
        "    return test_loss.item(), correct, test_dice_coef\n",
        "    \n",
        "#%%Main\n",
        "if  __name__ == \"__main__\" :   \n",
        "    # Version of Pytorch\n",
        "    print(\"Pytorch Version:\", torch.__version__)\n",
        "    \n",
        "    # Training args\n",
        "    parser = argparse.ArgumentParser(description='Fully Convolutional Network')\n",
        "    parser.add_argument('--batch-size', type=int, default=1, metavar='N',\n",
        "                        help='input batch size for training (default: 64)')\n",
        "    parser.add_argument('--test-batch-size', type=int, default=1, metavar='N',\n",
        "                        help='input batch size for testing (default: 1000)')\n",
        "    parser.add_argument('--epochs', type=int, default=100, metavar='N',\n",
        "                        help='number of epochs to train (default: 10)')\n",
        "    parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n",
        "                        help='learning rate (default: 0.01)')\n",
        "    parser.add_argument('--momentum', type=float, default=0.99, metavar='M',\n",
        "                        help='SGD momentum (default: 0.5)')\n",
        "    parser.add_argument('--no-cuda', action='store_true', default=True,\n",
        "                        help='disables CUDA training')\n",
        "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
        "                        help='random seed (default: 1)')\n",
        "    parser.add_argument('--log-interval', type=int, default=1000, metavar='N',\n",
        "                        help='how many batches to wait before logging training status')\n",
        "    \n",
        "    parser.add_argument('--save-model', action='store_true', default=True,\n",
        "                        help='For Saving the current Model')\n",
        "    \n",
        "    args = parser.parse_known_args()[0]\n",
        "    #args = parser.parse_args()\n",
        "\n",
        "    # Use GPU if it is available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    #data_root = './drive/My Drive/patches'\n",
        "    \n",
        "    \n",
        "    # Create FCN\n",
        "    model = iterativeFCN().to('cuda')\n",
        "    model.load_state_dict(torch.load('./drive/My Drive/IterativeFCN_best_train.pth'))\n",
        "     \n",
        "    data_root = './drive/My Drive/crop_isotropic_dataset'\n",
        "    \n",
        "    batch_size = args.batch_size\n",
        "    batch_size_valid = batch_size\n",
        "\n",
        "    \n",
        "    train_dataset = CSI_Dataset(data_root, subset='train')\n",
        "    test_dataset = CSI_Dataset(data_root, subset='test')\n",
        "  \n",
        "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1 , shuffle=True)\n",
        "    \n",
        "    #optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "    \n",
        "    train_loss = []\n",
        "    test_loss = []\n",
        "    train_acc = []\n",
        "    test_acc = []\n",
        "    train_dice = []\n",
        "    test_dice = []\n",
        "    best_train_dice = 0\n",
        "    best_test_dice = 0\n",
        "    \n",
        "    total_iteration = 20000\n",
        "    train_interval = 50\n",
        "    eval_interval =  10\n",
        "    \n",
        "    # Start Training\n",
        "    for epoch in range(int(total_iteration/train_interval)):\n",
        "        \n",
        "        start_time = time.time()\n",
        "        epoch_train_dice = []\n",
        "        epoch_test_dice = []\n",
        "        epoch_train_loss = []\n",
        "        epoch_test_loss = []\n",
        "        epoch_train_accuracy = 0.\n",
        "        epoch_test_accuracy = 0.\n",
        "        correct_train_count = 0\n",
        "        correct_test_count = 0\n",
        "        \n",
        "        #training process\n",
        "        for i in range(train_interval):\n",
        "            img_patch, ins_patch, gt_patch, weight, c_label = next(iter(train_loader))\n",
        "            t_loss, t_c, t_dice = train_single(args, model, device, img_patch, ins_patch, gt_patch, weight, c_label, optimizer)\n",
        "            epoch_train_loss.append(t_loss)\n",
        "            epoch_train_dice.append(t_dice)\n",
        "            correct_train_count+=t_c\n",
        "            \n",
        "        epoch_train_accuracy = correct_train_count/train_interval\n",
        "        avg_train_loss = sum(epoch_train_loss) / len(epoch_train_loss)\n",
        "        avg_train_dice = sum(epoch_train_dice) / len(epoch_train_dice)\n",
        "        \n",
        "        print('Train Epoch: {} \\t Loss: {:.6f}\\t acc: {:.6f}%\\t dice: {:.6f}%'.format(epoch\n",
        "              , avg_train_loss\n",
        "              , epoch_train_accuracy*100\n",
        "              , avg_train_dice*100))\n",
        "\n",
        "        if avg_train_dice > best_train_dice:\n",
        "            best_train_dice = avg_train_dice\n",
        "            print('--- Saving model at Avg Train Dice:{:.2f}%  ---'.format(avg_train_dice*100))\n",
        "            torch.save(model.state_dict(),'./drive/My Drive/IterativeFCN_best_train.pth')\n",
        "        \n",
        "        #validation process\n",
        "        for i in range(eval_interval):\n",
        "            img_patch, ins_patch, gt_patch, weight, c_label = next(iter(test_loader))\n",
        "            v_loss, v_c, v_dice = test_single(args, model, device, img_patch, ins_patch, gt_patch, weight, c_label)\n",
        "            epoch_test_loss.append(v_loss)\n",
        "            epoch_test_dice.append(v_dice)\n",
        "            correct_test_count+=v_c\n",
        "            \n",
        "        epoch_test_accuracy = correct_test_count/eval_interval\n",
        "        avg_test_loss = sum(epoch_test_loss) / len(epoch_test_loss)\n",
        "        avg_test_dice = sum(epoch_test_dice) / len(epoch_test_dice)\n",
        "        \n",
        "        \n",
        "        print('Validation Epoch: {} \\t Loss: {:.6f}\\t acc: {:.6f}%\\t dice: {:.6f}%'.format(epoch\n",
        "              , avg_test_loss\n",
        "              , epoch_test_accuracy*100\n",
        "              , avg_test_dice*100))\n",
        "        \n",
        "        if avg_test_dice > best_test_dice:\n",
        "            best_test_dice = avg_test_dice\n",
        "            print('--- Saving model at Avg Train Dice:{:.2f}%  ---'.format(avg_test_dice*100))\n",
        "            torch.save(model.state_dict(),'./drive/My Drive/IterativeFCN_best.pth')\n",
        "        \n",
        "        print('-------------------------------------------------------')\n",
        "        \n",
        "        train_loss.append(epoch_train_loss)\n",
        "        test_loss.append(epoch_test_loss)\n",
        "        train_acc.append(epoch_train_accuracy)\n",
        "        test_acc.append(epoch_test_accuracy)\n",
        "        \n",
        "\n",
        "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "        \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "Pytorch Version: 1.2.0\n",
            "num_channel 64\n",
            "elastic deform\n",
            "gaussian blur\n",
            "gaussian noise\n",
            "87.24573659338401 %\n",
            "13557.08984375 0.4676624536514282\n",
            "gaussian noise\n",
            "90.00274865512232 %\n",
            "14539.84375 0.3186974823474884\n",
            "elastic deform\n",
            "gaussian blur\n",
            "gaussian noise\n",
            "Random crop along z-axis\n",
            "88.54843099895011 %\n",
            "15042.0146484375 0.194111630320549\n",
            "gaussian blur\n",
            "gaussian noise\n",
            "Random crop along z-axis\n",
            "82.82974251182344 %\n",
            "17478.06640625 0.2779172956943512\n",
            "89.36655267871683 %\n",
            "21214.08984375 0.17388691008090973\n",
            "99.78972658722262 %\n",
            "11411.125 1.5011028051376343\n",
            "Random crop along z-axis\n",
            "84.64423669036556 %\n",
            "17002.46875 0.27331408858299255\n",
            "gaussian blur\n",
            "gaussian noise\n",
            "86.25191351760436 %\n",
            "20494.37109375 0.2541404664516449\n",
            "elastic deform\n",
            "gaussian blur\n",
            "gaussian noise\n",
            "78.12580747035686 %\n",
            "14312.701171875 0.12618856132030487\n",
            "elastic deform\n",
            "gaussian blur\n",
            "gaussian noise\n",
            "68.46269881176066 %\n",
            "18140.423828125 0.10316625237464905\n",
            "elastic deform\n",
            "88.0391836734694 %\n",
            "12652.064453125 0.11868271231651306\n",
            "gaussian noise\n",
            "99.89302648179326 %\n",
            "10283.2734375 1.1041202545166016\n",
            "elastic deform\n",
            "gaussian blur\n",
            "92.15031549777498 %\n",
            "36268.484375 0.0998172014951706\n",
            "gaussian blur\n",
            "92.00839328537171 %\n",
            "16593.62109375 0.04524650797247887\n",
            "gaussian blur\n",
            "Random crop along z-axis\n",
            "94.28443801582574 %\n",
            "19405.7265625 0.19990374147891998\n",
            "elastic deform\n",
            "gaussian noise\n",
            "Random crop along z-axis\n",
            "93.3151858918838 %\n",
            "22755.48828125 0.04345989599823952\n",
            "elastic deform\n",
            "gaussian noise\n",
            "Random crop along z-axis\n",
            "99.59150060805699 %\n",
            "11664.298828125 1.4539663791656494\n",
            "elastic deform\n",
            "gaussian noise\n",
            "Random crop along z-axis\n",
            "99.63811082556865 %\n",
            "10599.2041015625 1.3133231401443481\n",
            "gaussian noise\n",
            "Random crop along z-axis\n",
            "85.29258292955647 %\n",
            "20047.650390625 0.18860599398612976\n",
            "gaussian blur\n",
            "Random crop along z-axis\n",
            "77.73113545612777 %\n",
            "17633.349609375 0.15589900314807892\n",
            "gaussian noise\n",
            "75.1079084719438 %\n",
            "15867.2802734375 0.1258460432291031\n",
            "gaussian blur\n",
            "gaussian noise\n",
            "Random crop along z-axis\n",
            "78.65815707579513 %\n",
            "21676.146484375 0.298736035823822\n",
            "elastic deform\n",
            "gaussian blur\n",
            "Random crop along z-axis\n",
            "76.17613348615293 %\n",
            "17819.23046875 0.35541629791259766\n",
            "gaussian blur\n",
            "gaussian noise\n",
            "99.54790252589734 %\n",
            "10347.205078125 1.7259477376937866\n",
            "gaussian blur\n",
            "Random crop along z-axis\n",
            "87.34932998136966 %\n",
            "25608.291015625 0.16250599920749664\n",
            "gaussian blur\n",
            "gaussian noise\n",
            "Random crop along z-axis\n",
            "88.25644797240749 %\n",
            "26089.46875 0.24115775525569916\n",
            "elastic deform\n",
            "76.57154026583268 %\n",
            "15328.1669921875 0.4749818742275238\n",
            "gaussian blur\n",
            "Random crop along z-axis\n",
            "88.6498011628641 %\n",
            "20236.857421875 0.06646502017974854\n",
            "gaussian noise\n",
            "55.300359404415545 %\n",
            "22486.072265625 0.27075880765914917\n",
            "elastic deform\n",
            "gaussian blur\n",
            "Random crop along z-axis\n",
            "99.74967918159217 %\n",
            "10481.0732421875 1.4799959659576416\n",
            "Random crop along z-axis\n",
            "91.11520137696466 %\n",
            "54327.1484375 0.40827327966690063\n",
            "elastic deform\n",
            "Random crop along z-axis\n",
            "87.16895012979272 %\n",
            "26338.6953125 0.08507385104894638\n",
            "elastic deform\n",
            "gaussian blur\n",
            "82.81716294183964 %\n",
            "15821.501953125 0.20510785281658173\n",
            "Random crop along z-axis\n",
            "73.29433437833296 %\n",
            "21027.6484375 0.09963774681091309\n",
            "elastic deform\n",
            "gaussian blur\n",
            "gaussian noise\n",
            "86.00557917109458 %\n",
            "19858.458984375 0.12779463827610016\n",
            "elastic deform\n",
            "gaussian noise\n",
            "Random crop along z-axis\n",
            "99.77959800051612 %\n",
            "11395.064453125 1.2780017852783203\n",
            "elastic deform\n",
            "Random crop along z-axis\n",
            "37.43489583333333 %\n",
            "19656.181640625 1.9072210788726807\n",
            "elastic deform\n",
            "Random crop along z-axis\n",
            "83.60936777925195 %\n",
            "32413.515625 0.19919925928115845\n",
            "elastic deform\n",
            "gaussian blur\n",
            "gaussian noise\n",
            "83.95673498366332 %\n",
            "22402.15625 0.12115292996168137\n",
            "gaussian noise\n",
            "Random crop along z-axis\n",
            "93.75755482645485 %\n",
            "21014.255859375 0.037319865077733994\n",
            "gaussian blur\n",
            "77.03326002763559 %\n",
            "17117.26171875 0.0898936316370964\n",
            "99.49790935339715 %\n",
            "10167.9482421875 1.2981489896774292\n",
            "gaussian blur\n",
            "76.08669727505813 %\n",
            "19813.76953125 0.146635964512825\n",
            "gaussian blur\n",
            "gaussian noise\n",
            "Random crop along z-axis\n",
            "66.89737334770523 %\n",
            "22668.015625 0.10524928569793701\n",
            "gaussian noise\n",
            "Random crop along z-axis\n",
            "78.69041148447741 %\n",
            "17023.189453125 0.13410307466983795\n",
            "elastic deform\n",
            "Random crop along z-axis\n",
            "76.7758140104757 %\n",
            "23137.02734375 0.12656250596046448\n",
            "elastic deform\n",
            "gaussian blur\n",
            "Random crop along z-axis\n",
            "85.05299890948746 %\n",
            "21298.75390625 0.11136489361524582\n",
            "elastic deform\n",
            "gaussian blur\n",
            "gaussian noise\n",
            "99.78381250752642 %\n",
            "10162.080078125 1.619048833847046\n",
            "elastic deform\n",
            "gaussian blur\n",
            "gaussian noise\n",
            "45.83323853941531 %\n",
            "12498.88671875 0.7518624067306519\n",
            "elastic deform\n",
            "gaussian blur\n",
            "gaussian noise\n",
            "88.62857263033924 %\n",
            "21581.1328125 0.23353682458400726\n",
            "Train Epoch: 0 \t Loss: 18935.610879\t acc: 78.000000%\t dice: 84.315964%\n",
            "--- Saving model at Avg Train Dice:84.32%  ---\n",
            "gaussian blur\n",
            "Random crop along z-axis\n",
            "1.1789275127997845 %\n",
            "213411.140625 0.1562059074640274\n",
            "1.2280906299794023 %\n",
            "164591.1875 0.02814416028559208\n",
            "elastic deform\n",
            "gaussian blur\n",
            "4.114492692106343 %\n",
            "420968.96875 0.012473871000111103\n",
            "gaussian blur\n",
            "gaussian noise\n",
            "0.7486936854966595 %\n",
            "244392.125 0.017656737938523293\n",
            "elastic deform\n",
            "gaussian blur\n",
            "gaussian noise\n",
            "1.614854042038508 %\n",
            "157930.09375 0.002721552737057209\n",
            "gaussian blur\n",
            "99.76426953188479 %\n",
            "7245.18115234375 5.566054344177246\n",
            "elastic deform\n",
            "gaussian blur\n",
            "Random crop along z-axis\n",
            "1.2604966786628709 %\n",
            "355889.90625 0.019997742027044296\n",
            "gaussian blur\n",
            "0.018843925189616997 %\n",
            "146624.078125 0.04820672795176506\n",
            "elastic deform\n",
            "gaussian blur\n",
            "0.5745388569700636 %\n",
            "228477.9375 0.003801648737862706\n",
            "elastic deform\n",
            "1.996647604022875 %\n",
            "141120.265625 0.00019832431280519813\n",
            "Validation Epoch: 0 \t Loss: 208065.673145\t acc: 90.000000%\t dice: 11.249986%\n",
            "-------------------------------------------------------\n",
            "--- 960.498765707016 seconds ---\n",
            "gaussian blur\n",
            "gaussian noise\n",
            "3.127197965698209 %\n",
            "14857.798828125 0.3989015817642212\n",
            "gaussian noise\n",
            "86.0797984405204 %\n",
            "13222.0537109375 0.10426818579435349\n",
            "gaussian noise\n",
            "Random crop along z-axis\n",
            "92.77071128670687 %\n",
            "29599.2578125 0.3291895389556885\n",
            "elastic deform\n",
            "gaussian blur\n",
            "99.85600270087455 %\n",
            "12151.580078125 0.7109093070030212\n",
            "elastic deform\n",
            "gaussian blur\n",
            "86.34308109737715 %\n",
            "15371.9326171875 0.3813827335834503\n",
            "elastic deform\n",
            "gaussian noise\n",
            "Random crop along z-axis\n",
            "85.29203181196495 %\n",
            "15112.330078125 0.21105517446994781\n",
            "gaussian blur\n",
            "89.41873569165563 %\n",
            "20516.462890625 0.39728444814682007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtEDTSx2UMC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"training:\", len(train_loss))\n",
        "print(\"validation:\", len(test_loss))\n",
        "x = list(range(1, len(train_loss)))\n",
        "#plot train/validation loss versus epoch\n",
        "plt.figure()\n",
        "plt.title(\"Train/Validation Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Total Loss\")\n",
        "plt.plot(x, train_loss,label=\"train loss\")\n",
        "plt.plot(x, test_loss, color='red', label=\"validation loss\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#plot train/validation loss versus epoch\n",
        "plt.figure()\n",
        "plt.title(\"Train/Validation Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.plot(x, train_acc,label=\"train acc\")\n",
        "plt.plot(x, test_acc, color='red', label=\"validation acc\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}