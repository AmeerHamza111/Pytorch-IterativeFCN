{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main_191015.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leohsuofnthu/Pytorch-IterativeFCN/blob/master/Main_191015.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lTjJqrezvcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyCHkxyLz7r2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install SimpleITK\n",
        "!pip install medpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O95a1aStKHRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Training and Evaluation\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu Sep 19 11:21:22 2019\n",
        "\n",
        "@author: Gabriel Hsu\n",
        "\"\"\"\n",
        "from __future__ import print_function, division\n",
        "import os\n",
        "import argparse\n",
        "import time\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from model import iterativeFCN\n",
        "from dataset import CSI_Dataset\n",
        "from metrics import DiceCoeff, ASSD\n",
        "\n",
        "import SimpleITK as sitk\n",
        "\n",
        "def seg_loss(pred, target, weight):\n",
        "    FP = torch.sum(weight*(1-target)*pred)\n",
        "    FN = torch.sum(weight*(1-pred)*target)\n",
        "    return FP, FN\n",
        "    \n",
        "#%%\n",
        "def train_single(args, model, device, img_patch, ins_patch, gt_patch, weight, c_label, optimizer):\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "  \n",
        "    model.train()\n",
        "    correct = 0\n",
        "    \n",
        "    img_patch = img_patch.float()\n",
        "    ins_patch = ins_patch.float()\n",
        "    gt_patch = gt_patch.float()\n",
        "    weight = weight.float()\n",
        "    c_label = c_label.float()\n",
        "    \n",
        "    \n",
        "    #pick a random scan\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    #concatenate the img_patch and ins_patch\n",
        "    input_patch = torch.cat((img_patch, ins_patch), dim=1)\n",
        "    input_patch, gt_patch, weight, c_label = input_patch.to(device), gt_patch.to(device), weight.to(device), c_label.to(device)\n",
        "    \n",
        "    \n",
        "    S, C = model(input_patch.float())        \n",
        "    \n",
        "    \n",
        "    #Calculate DiceCoeff\n",
        "    pred = torch.round(S).detach()\n",
        "    train_dice_coef =  DiceCoeff(pred, gt_patch.detach())\n",
        "    \n",
        "    print( train_dice_coef*100, '%')\n",
        "    \n",
        "    #compute the loss\n",
        "    lamda = 0.1\n",
        "    \n",
        "    #segloss \n",
        "    FP, FN = seg_loss(S, gt_patch, weight) \n",
        " \n",
        "    s_loss = lamda*FP + FN\n",
        "    \n",
        "    c_loss = F.binary_cross_entropy(torch.unsqueeze(C, dim=0), c_label)\n",
        "\n",
        "    print(s_loss.item(), c_loss.item())\n",
        "    \n",
        "    train_loss = s_loss + c_loss\n",
        "    \n",
        "    \n",
        "    \n",
        "    if C.round() == c_label:\n",
        "        correct = 1\n",
        "    \n",
        "    #optimize the parameters\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return train_loss.item(), correct, train_dice_coef\n",
        "\n",
        "def test_single(args, model, device, img_patch, ins_patch, gt_patch, weight, c_label):\n",
        "    \n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    \n",
        "    img_patch = img_patch.float()\n",
        "    ins_patch = ins_patch.float()\n",
        "    gt_patch = gt_patch.float()\n",
        "    weight = weight.float()\n",
        "    c_label = c_label.float()\n",
        "    \n",
        "    input_patch = torch.cat((img_patch, ins_patch), dim=1)\n",
        "    input_patch, gt_patch, weight, c_label = input_patch.to(device), gt_patch.to(device), weight.to(device), c_label.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        S, C = model(input_patch.float())\n",
        "        \n",
        "    \"\"\"\n",
        "    pred = torch.squeeze(S.to('cpu'))\n",
        "    sitk.WriteImage(sitk.GetImageFromArray(pred.numpy()), './pred.nrrd', True)\n",
        "    \n",
        "    gtt = torch.squeeze(gt_patch.to('cpu'))\n",
        "    sitk.WriteImage(sitk.GetImageFromArray(gtt.numpy()), './gt.nrrd', True)\n",
        "    \"\"\"\n",
        "    \n",
        "    #Calculate DiceCoeff\n",
        "    pred = torch.round(S).detach()\n",
        "    test_dice_coef =  DiceCoeff(pred, gt_patch.detach())  \n",
        "    \n",
        "    print( test_dice_coef*100, '%')\n",
        "    \n",
        "    #compute the loss\n",
        "    lamda = 0.1\n",
        "    \n",
        "    #segloss \n",
        "    FP, FN = seg_loss(S, gt_patch, weight) \n",
        "    \n",
        "    s_loss = lamda*FP + FN\n",
        "    \n",
        "    c_loss = F.binary_cross_entropy(torch.unsqueeze(C, dim=0), c_label)\n",
        "    \n",
        "    \n",
        "    print(s_loss.item(), c_loss.item())\n",
        "    \n",
        "    if C.round() == c_label:\n",
        "        correct = 1\n",
        "\n",
        "    test_loss = s_loss + c_loss\n",
        "    \n",
        "        \n",
        "    return test_loss.item(), correct, test_dice_coef\n",
        "    \n",
        "#%%Main\n",
        "if  __name__ == \"__main__\" :   \n",
        "    # Version of Pytorch\n",
        "    print(\"Pytorch Version:\", torch.__version__)\n",
        "    \n",
        "    # Training args\n",
        "    parser = argparse.ArgumentParser(description='Fully Convolutional Network')\n",
        "    parser.add_argument('--batch-size', type=int, default=1, metavar='N',\n",
        "                        help='input batch size for training (default: 64)')\n",
        "    parser.add_argument('--test-batch-size', type=int, default=1, metavar='N',\n",
        "                        help='input batch size for testing (default: 1000)')\n",
        "    parser.add_argument('--epochs', type=int, default=100, metavar='N',\n",
        "                        help='number of epochs to train (default: 10)')\n",
        "    parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n",
        "                        help='learning rate (default: 0.01)')\n",
        "    parser.add_argument('--momentum', type=float, default=0.99, metavar='M',\n",
        "                        help='SGD momentum (default: 0.5)')\n",
        "    parser.add_argument('--no-cuda', action='store_true', default=True,\n",
        "                        help='disables CUDA training')\n",
        "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
        "                        help='random seed (default: 1)')\n",
        "    parser.add_argument('--log-interval', type=int, default=1000, metavar='N',\n",
        "                        help='how many batches to wait before logging training status')\n",
        "    \n",
        "    parser.add_argument('--save-model', action='store_true', default=True,\n",
        "                        help='For Saving the current Model')\n",
        "    \n",
        "    args = parser.parse_known_args()[0]\n",
        "    #args = parser.parse_args()\n",
        "\n",
        "    # Use GPU if it is available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    #data_root = './drive/My Drive/patches'\n",
        "    \n",
        "    \n",
        "    # Create FCN\n",
        "    model = iterativeFCN().to('cuda')\n",
        "    model.load_state_dict(torch.load('./drive/My Drive/IterativeFCN_best_train.pth'))\n",
        "     \n",
        "    data_root = './drive/My Drive/crop_isotropic_dataset'\n",
        "    \n",
        "    batch_size = args.batch_size\n",
        "    batch_size_valid = batch_size\n",
        "\n",
        "    \n",
        "    train_dataset = CSI_Dataset(data_root, subset='train')\n",
        "    test_dataset = CSI_Dataset(data_root, subset='test')\n",
        "  \n",
        "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1 , shuffle=True)\n",
        "    \n",
        "    #optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "    \n",
        "    train_loss = []\n",
        "    test_loss = []\n",
        "    train_acc = []\n",
        "    test_acc = []\n",
        "    train_dice = []\n",
        "    test_dice = []\n",
        "    best_train_dice = 0\n",
        "    best_test_dice = 0\n",
        "    \n",
        "    total_iteration = 20000\n",
        "    train_interval = 50\n",
        "    eval_interval =  10\n",
        "    \n",
        "    # Start Training\n",
        "    for epoch in range(int(total_iteration/train_interval)):\n",
        "        \n",
        "        start_time = time.time()\n",
        "        epoch_train_dice = []\n",
        "        epoch_test_dice = []\n",
        "        epoch_train_loss = []\n",
        "        epoch_test_loss = []\n",
        "        epoch_train_accuracy = 0.\n",
        "        epoch_test_accuracy = 0.\n",
        "        correct_train_count = 0\n",
        "        correct_test_count = 0\n",
        "        \n",
        "        #training process\n",
        "        for i in range(train_interval):\n",
        "            img_patch, ins_patch, gt_patch, weight, c_label = next(iter(train_loader))\n",
        "            t_loss, t_c, t_dice = train_single(args, model, device, img_patch, ins_patch, gt_patch, weight, c_label, optimizer)\n",
        "            epoch_train_loss.append(t_loss)\n",
        "            epoch_train_dice.append(t_dice)\n",
        "            correct_train_count+=t_c\n",
        "            \n",
        "        epoch_train_accuracy = correct_train_count/train_interval\n",
        "        avg_train_loss = sum(epoch_train_loss) / len(epoch_train_loss)\n",
        "        avg_train_dice = sum(epoch_train_dice) / len(epoch_train_dice)\n",
        "        \n",
        "        print('Train Epoch: {} \\t Loss: {:.6f}\\t acc: {:.6f}%\\t dice: {:.6f}%'.format(epoch\n",
        "              , avg_train_loss\n",
        "              , epoch_train_accuracy*100\n",
        "              , avg_train_dice*100))\n",
        "\n",
        "        if avg_train_dice > best_train_dice:\n",
        "            best_test_dice = avg_train_dice\n",
        "            print('--- Saving model at Avg Train Dice:{:.2f}%  ---'.format(avg_train_dice*100))\n",
        "            torch.save(model.state_dict(),'./drive/My Drive/IterativeFCN_best_train.pth')\n",
        "        \n",
        "        #validation process\n",
        "        for i in range(eval_interval):\n",
        "            img_patch, ins_patch, gt_patch, weight, c_label = next(iter(test_loader))\n",
        "            v_loss, v_c, v_dice = test_single(args, model, device, img_patch, ins_patch, gt_patch, weight, c_label)\n",
        "            epoch_test_loss.append(v_loss)\n",
        "            epoch_test_dice.append(v_dice)\n",
        "            correct_test_count+=v_c\n",
        "            \n",
        "        epoch_test_accuracy = correct_test_count/eval_interval\n",
        "        avg_test_loss = sum(epoch_test_loss) / len(epoch_test_loss)\n",
        "        avg_test_dice = sum(epoch_test_dice) / len(epoch_test_dice)\n",
        "        \n",
        "        \n",
        "        print('Validation Epoch: {} \\t Loss: {:.6f}\\t acc: {:.6f}%\\t dice: {:.6f}%'.format(epoch\n",
        "              , avg_test_loss\n",
        "              , epoch_test_accuracy*100\n",
        "              , avg_test_dice*100))\n",
        "        \n",
        "        if avg_test_dice > best_test_dice:\n",
        "            best_test_dice = avg_test_dice\n",
        "            print('--- Saving model at Avg Train Dice:{:.2f}%  ---'.format(avg_test_dice*100))\n",
        "            torch.save(model.state_dict(),'./drive/My Drive/IterativeFCN_best.pth')\n",
        "        \n",
        "        print('-------------------------------------------------------')\n",
        "        \n",
        "        train_loss.append(epoch_train_loss)\n",
        "        test_loss.append(epoch_test_loss)\n",
        "        train_acc.append(epoch_train_accuracy)\n",
        "        test_acc.append(epoch_test_accuracy)\n",
        "        \n",
        "\n",
        "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "        \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtEDTSx2UMC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"training:\", len(train_loss))\n",
        "print(\"validation:\", len(test_loss))\n",
        "x = list(range(1, len(train_loss)))\n",
        "#plot train/validation loss versus epoch\n",
        "plt.figure()\n",
        "plt.title(\"Train/Validation Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Total Loss\")\n",
        "plt.plot(x, train_loss,label=\"train loss\")\n",
        "plt.plot(x, test_loss, color='red', label=\"validation loss\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#plot train/validation loss versus epoch\n",
        "plt.figure()\n",
        "plt.title(\"Train/Validation Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.plot(x, train_acc,label=\"train acc\")\n",
        "plt.plot(x, test_acc, color='red', label=\"validation acc\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}